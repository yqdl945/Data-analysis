# 数据分析45讲



## 05|Pandas

- Series
- DataFrame

 ~~~
import pandas as pd
from pandas import DataFrame,Series
# 数据清洗
## 1.删除不必要值——drop(放入要删除的目标参数)
df1 = df1.drop(columns = ['XXX'])
df2 = df1.drop(index = ['YYY'])
## 2.重命名——rename("错误名称":"正确名称")
df2.rename(columns={'Chinese': 'YuWen', 'English': 'Yingyu'}, inplace = True)
## 3.去除重复值——drop_duplicates()
df = df.drop_duplicates() 
## 4.更改格式
### 4.1.astype('str')
df2['Chinese'].astype('str') 
df2['Chinese'].astype(np.int64) 
### 4.2 srip("也可以添加符号用于删除数据中的特殊符号") #默认删除左右空格
df2['Chinese']=df2['Chinese'].map(str.strip())
df2['Chinese']=df2['Chinese'].str.strip('$')

## 找空值——isnull()
 ~~~

### apply()函数清洗
### describe()输出结果！
### lambda

~~~
## merget(a,b,on = "基于目标")
## merget(a,b,how = "inner")
## left/right
## outer
~~~
### 基于SQL打开——pandasql
~~~
import pandas as pd
from pandas import DataFrame
from pandasql import sqldf, load_meat, load_births
df1 = DataFrame({'name':['ZhangFei', 'GuanYu', 'a', 'b', 'c'], 'data1':range(5)})
pysqldf = lambda sql: sqldf(sql, globals())
sql = "select * from df1 where name ='ZhangFei'"
print pysqldf(sql)

~~~

## 15|数据可视化

- 视图分类：
  - 比较
  - 联系
  - 构成
  - 分布
- 视图：![img](https://static001.geekbang.org/resource/image/46/75/4673a17085302cfe9177f8ee687ac675.png)

- matplotlib使用：

  ~~~python
  import matplotlib.pyplot as plt
  #散点图：
  plt.scatter(x,y,marker = None)
  #marker是点的样子？
  # 绘图步骤
  x = 
  y = 
  plt.scatter(x,y,marker = '?')
  plt.show(不填参数！！)
  ~~~

  - 默认形状是长方形

- seaborn

  ~~~python
  import seaborn as sns
  # 绘图:
  df = DataFrame(,)
  sns.joinplot(x = 'x',y = 'y',data = df,kind = 'scatter')
  plt.show()
  # kind 作用？
  ~~~

  - 默认形状是正方形 + 变量分布情况

  

  ........

  ![img](https://static001.geekbang.org/resource/image/8e/d2/8ed2addb00a4329dd63bba669f427fd2.png)

  

## 二 算法

### | 决策树  上

- 将经验总结出来，根据因素决定结果

  - 构造：根节点；内部节点；叶节点（停止，没有子节点）——（父子关系）
  - 剪枝：预剪枝（构造时剪枝）；后剪枝（生成决策树之后进行剪枝）
    - 防止“过拟合”——模型训练的过于完美，在实际应用中存在“死板”现象造成分类错误
      - 训练集中，样本量小——模型泛化能力差

- 选择哪个属性作为根节点；选择那些属性作为后继节点；什么时候停止并得到目标值

  - 纯度（目标变量分歧最小）；信息熵(信息的不确定度)

  - 信息熵数学公式

  - 熵越大，纯度越低

    - 经典“不纯度”指标：信息增益（ID3）、信息增益率（c4.5）、基尼指数（Cart算法）

      - 信息增益(ID3)：缺点：	倾向于选择取值多的属性，（有些属性**对分类无帮助**，可能会被选为**最优属性**
        -  改进：信息增益率(C4.5) 信息增益/属性熵
        - 悲观剪枝(PEP)--不需要单独测试数据集
        - 离散化处理连续属性--选择具有最高信息增益的划分对应的阈值
        - 处理缺失值--

    - 综合：ID3 方法简单，-对噪声敏感

      ​			C4.5需要对数据集进行多次扫描，效率较低！

      

### |决策树  下

